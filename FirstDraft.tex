\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{booktabs}
\usepackage[style=alphabetic, backend=biber]{biblatex}

\graphicspath{ {./images/} }

\addbibresource{references.bib}

% Preamble
\setlength{\parindent}{0pt}
\linespread{1.5}

% Document Information
\title{Ray Tracing Voxels with Hardware Acceleration in Real-Time \\
    \vspace{1cm}
    \large Is hardware accelerated voxel ray possible on consumer hardware for real-time applications?}
\author{Srijan Dhungana}
\date{2024}

% Begin Document
\begin{document}

% Title Page
\maketitle
\clearpage

% Table of Contents
\tableofcontents
\clearpage


\clearpage

\section{Motivation}

My first introduction to ray tracing was when NVIDIA announced their RTX series GPUs in 2018.
The idea of simulating light rays in real-time was unreal and the results were stunning.
I wanted to make my own hardware ray tracer and so I was introduced to computer graphics.
The aesthetics of voxels based games have been fascinating and I wanted to combine the two.
However, when researching, I found that there was no performance analysis of hardware accelerated voxel ray tracing.

\section{Introduction}

\subsection{Ray Tracing}

Ray tracing is a method to calculate where a given ray (line), intersects
with the environment. This is useful to simulate light rays because of how light behaves. It is used in film
production, video games, optics, medical imaging, architectural visualization,
and many other fields. Physically light rays bounce in the environment, thus
ray tracing is used to calculate the position of intersection where a light ray
hits the environment. Then the programmer is free to repeat the process
and simulate the ray bouncing off into other directions. This process is a
highly parallelizable process, thus it is perfectly suited for GPUs which have
thousands of cores. However, due to how computationally expensive the
process is, it is not feasible to do in real-time without dedicated hardware
acceleration. Due to those limitations, it was only used in non-real-time
applications such as film production. Hardware acceleration ray tracing was introduced in 2018 by Nvidia.
Since then, ray tracing has been possible in real-time and further supported by AMD and
Intel GPUs. This has allowed real-time applications to leverage ray-tracing such as video games.

\subsection{Voxels}

Voxels are a way to represent 3D data. It is similar to pixels in 2D images,
but in 3D space. Essentially, voxels are cubes that are located in 3D space.
They are used in medical imaging, simulations, and video games; they have
similar applications to ray tracing. Voxels are convenient, because they represent
volumetric data, which is difficult to represent with traditional with polygons that the GPU is designed to handle.
Terrain, and medical imaging data are examples of volumetric data. 
The sensors uniformly sample the 3D space and store the data in a 3D grid,
making voxels a perfect representation of the data.
Each voxel can contain data, such as color, or density captured from the sensors,
which can be utilized in simulations or visualizations.

\subsection{Research Question}

The research question is: Is hardware accelerated voxel ray possible on consumer hardware for real-time applications?
Real-time applications considered are video games, and visualizations that utilize volumetric data in the form of voxels.
These are the factors that will be considered when evaluating the possibility:
\begin{itemize}
    \itemsep0em
    \item Can the hardware a reasonable number of voxels? (1-10 million)
    \item Does the memory consumption exceed the available memory on the GPU? (8GB)
\end{itemize}

Moreover, this essay attempts to analyze the GPU hardware bottlenecks that limit the performance of voxel ray tracing.

\section{Background Information}

\subsection{Mathematics of Ray Tracing}
\subsubsection{The Ray Equation}

A ray is defined by a point and a direction. The equation of a ray is given by:

\begin{equation}
    R(t) = \vec{o} + t\vec{d}
\end{equation}

where $\vec{o}$ is the origin of the ray, $\vec{d}$ is the direction of the ray, and $t$ is the distance from the origin.
The function $R(t)$ gives the position of the ray at distance $t$ from the origin.
With this equation, any point along the ray can calculated.

\subsubsection{The Intersection Function}

Whenever a ray intersects with a surface, the point of intersection is given by the equation:

\begin{equation}
    R(t) = I(t)
\end{equation}

where $I(t)$ is the intersection function of the surface. To locate the point of intersection,
solving for $t$ is necessary by equating the ray equation with the intersection function. 
If there are solutions for $t$, then the ray intersects with the surface. However, 
if $t$ is negative, then the intersection is opposite to the direction of the ray, which is not desired,
hence negative solutions are discarded. The closest hit is usually desired thus smallest non-negative $t$ is chosen.

\subsection{Ray Tracing Algorithm}

The ray tracing algorithm is a recursive algorithm that calculates the color of a pixel by tracing rays into the scene from a virtual camera.
Ray tracing algorithm is as follows:

\begin{algorithm}[H]
\caption{Ray Tracing Algorithm}
\label{alg:TraceRay}
\tiny
\begin{algorithmic}[0]

\State $Emissive \gets 0$
\Procedure{TraceRay}{$direction, depth$}

    \If{$depth = 0$}
        \State \Return $0$ \Comment {Hit no light source after maximum depth}
    \EndIf

    \State $closestHit \gets \infty$
    \State $hitObject \gets null$

    \For{$object$ in $scene$}
        \State $hit \gets object.Intersect(direction)$
        \If{$hit < closestHit$}
            \State $closestHit \gets hit$
            \State $hitObject \gets object$
        \EndIf
    \EndFor

    \If{$closestHit = \infty$}
        \State $Emissive \gets 1$ \Comment {Sky is a light source}
        \State \Return $background$
    \EndIf
    \State $Emissive \gets hitObject.emissive$
    \If {$hitObject.emissive$} \Comment {If the object is a light source}
        \State \Return $hitObject.Color$
    \EndIf

    \State $newDirection \gets randomDirectionFromObject(hitObject)$

    \State \Return $object.Color * TraceRay(newDirection, depth - 1)$

\EndProcedure

\For{$pixel$ in $image$}
    \State $direction \gets getDirectionForPixel(pixel)$
    \State $color \gets TraceRay(direction, maxDepth) * Emissive$
    \State $image[pixel] \gets color$
    \State $Emissive \gets 0$ \Comment{Reset Emissive}
\EndFor

\end{algorithmic}
\end{algorithm}

The pseudocode in Algorithm \ref{alg:TraceRay} shows a simple recursive algorithm for ray tracing.
It finds the closest hit in the scene and if the object is emissive (light source), then the pixel is illuminated.
Note that if the path doesn't hit a light source, the path color is multiplied by 0, which results in a black pixel.

This recursive algorithm is repeated thousands of times for each pixel and the result is an image.
Even then, the image is an approximation of the real world because the algorithm only simulates a fraction of all the possible paths.
In this essay, this is the algorithm that will be used to simulate the paths of the rays.
This algorithm is split into multiple stages in the GPU.

\begin{figure}[H]
    \begin{center}
        \includegraphics[scale=0.22]{RayTracingImage}
    \end{center}
    \caption{Simplified visualization of the Algorithm \ref{alg:TraceRay}. \parencite{NVIDIA:Raytracing}}
    \label{fig:RayTracingImage}
\end{figure}

\subsection{Process of Ray Tracing on Hardware}
In this section, the ray tracing process on hardware is explained.

\subsubsection{Acceleration Structures}
Without any optimization algorithms, the intersection function has to be solved for every primitive in the scene to determine the closest hit. 
Primitives are smallest building blocks of the scene. The GPU only accepts triangles and axis aligned bounding boxes (AABB) as primitives.
AABBs are cuboids that are aligned in the x, y, and z axes.
Solving the intersection function for every primitive is computationally expensive for scenes with millions of primitives.
Hence, acceleration structures (AS) are used to reduce the number of times the intersection function is solved.
These structures are usually bounding volume hierarchies (BVH) that subdivide the scene into smaller parts until the smallest primitives are reached \parencite{NVIDIA:Raytracing}.
Bounding volumes are AABBs that enclose the primitives.
This method logarithmically decreases the number computation required to find the closest hit.

\begin{figure}[H]
    \includegraphics[scale=0.22]{BVH-Visualization}
    \caption{
        Bounding Volume Hierarchy of a bunny. 
        The bunny is divided into smaller bounding volumes until the individual triangles are reached.
        \parencite{Medium:BVH-Visualization}
        }
    \label{fig:BVH-Visualization}
\end{figure}

The BVH is a non-trivial tree structure that is constructed every object in the scene and requires ample memory.
When a ray enters a bounding volume (box), it is guaranteed that only the primitives inside the bounding volume are potential hits.
If the ray does not hit any primitives inside the bounding volume, then the ray goes to the previous bounding volume in the hierarchy and continues
to search for hits. This is repeated until the ray hits a primitive or exits the scene.

\subsubsection{Ray Tracing Pipeline}

The ray tracing pipeline is a series of steps that the GPU follows to use ray tracing.

\begin{figure}[H]
    \begin{center}
        \includegraphics[scale=0.25]{RayTracing-Pipeline}
    \end{center}
    \caption{
        The Ray Tracing Pipeline.
        Green boxes are programmable functions and grey boxes are fixed functions in hardware.
        \parencite{NVIDIA:DXR-Intro}
        }
    \label{fig:RayTracing-Pipeline}
\end{figure}

The ray tracing pipeline is shown in Figure \ref{fig:RayTracing-Pipeline}. 
Nearly all the steps in the pipeline are programmable, which allows the user to customize the pipeline.
Ray generation is the first step where the rays are generated from the camera in the correct direction and location.
The hardware acceleration structure traversal is the most critical step because it requires the most computation.
It is fully implemented in hardware and is not programmable until it reaches the leaf nodes of the BVH, after which the intersection stage is programmable.
For triangles primitives, the intersection stage is fixed in hardware, meaning it is not programmable.
For AABB primitives, the stage is programmable, which allows the user to run their own intersection function.
This is because, AABBs are meant to enclose user defined primitives.
For example, a sphere can be enclosed in an AABB and the acceleration structure traversal is hardware accelerated
until the AABB is hit. After hitting the AABB, the user defined intersection function for the sphere is invoked,
allowing the user to run their own sphere intersection function \parencite{NVIDIA:BVH-Patent}.
The intersection function needs to report the $t$ value of $R(t) = I(t)$ if there is an intersection.
The acceleration structure traversal and intersection stage are repeated until the closest hit is found,
that is the smallest non-negative $t$ value. Then the closest hit stage is invoked with the information
about the hit location and the object that was hit.
Closest hit can be used to shade the hit point and even generate new rays into different directions to simulate light bouncing. 

The anyhit stage is used to accept or discard hits. However, the anyhit stage is optional and can be omitted.
If no hit is found, the miss stage is invoked.
 Miss stage is used to shade the background if no hit is found.
\parencite{NVIDIA:RTGems2}

\section{Methodology}

\subsection{Utilizing Hardware Acceleration}

This essay will use AABBs as voxels, because the GPU only accepts either triangles or AABBs as primitives.
Voxels are easily represented as AABBs, because both are cuboids. 
The other alternative, representing voxels as triangles is not practical. Voxels have 6 faces, 2 triangles
are needed to represent each face, thus 12 triangles are needed to represent a voxel. This amounts to 
inefficent memory usage and computation. Usage of AABBs implies that the user has to program the intersection stage.

Acceleration structure generation is a black box in graphics APIs, where 
the primitives are supplied to the GPU and it constructs the AS. This is convenient to both the programmers and vendors, because
vendors can optimize the AS construction and traversal for their hardware and users are ensured that the AS has optimal performance.

\subsection{Optimizing the Intersection Function}
\label{sec:OptimizingIntersection}

There are complications to representing voxels as AABBs, because AABBs were meant to be extremely flexible to 
enclose any user defined primitive. This section provides an optimization for the intersection stage,
which involves approximating the closest hit.

\begin{figure}[H]
    \begin{center}
        \includegraphics[scale=0.5]{ClosestHit-Ambigous}
    \end{center}
    \caption{
        A scenario where the closest hit is not known by the GPU without invoking the user's intersection function.
        Even though the larger AABB is closer to the ray origin, the smaller AABB has a closer intersection
        with it's enclosed object.
    }
    \label{fig:ClosestHit-Ambigous}
\end{figure}

Figure \ref{fig:ClosestHit-Ambigous} shows a scenario where the GPU itself cannot determine the closest candidate just by
taking into account the AABBs. Because of this, every AABB along the ray has to be tested for intersection, which 
means the intersection stage can be invoked multiple times. For maximum performance, the the GPU should minimize 
the number of calculations performed in the intersection stage.

\begin{figure}[H]
    \begin{center}
        \includegraphics[scale=0.22]{ClosestHit-Approx}
    \end{center}
    \caption{
        Solving for closest hit candidate without an intersection test.
        Instead the distance from the ray origin to the AABB is calculated and the closest candidate is selected.
        }
    \label{fig:ClosestHit-Approx}
\end{figure}

Making the intersection stage efficient is trivial in this case.
Finding an exact solution for every candidate is not necessary. 
The GPU will pick the candidate with the smallest $t$ value reported, which can be approximated.
After the closest candidate is picked, the exact intersection point can be solved in the closest hit stage.
Only one exact solution is calculated, which is much more efficient than solving for every candidate.
Figure \ref{fig:ClosestHit-Approx} shows solving for the closest candiate without an intersection test.
In this case, since the voxels are never overlapping each other and of uniform size, the scenario in Figure \ref{fig:ClosestHit-Ambigous} is not possible.
Using this assumption, the closest voxel along the ray is guaranteed to have the closest intersection.
This method only involves calculating the distance from the ray origin to the voxel center and selecting the closest candidate.
Fetching the voxel center is an array fetch and calculating the distance is a simple vector instruction, which is very fast.
The candidate with the smallest distance is selected as the closest hit, as described in the previous section.
In the closest hit stage, there is enough information to calculate the exact intersection point.

\subsection{Memory Consumption}

The memory consumption is greater for AABBs than for voxels.
Unfortunately, the GPU requires AABBs to be used for hardware acceleration.
AABBs need two 3D vectors to represent the minimum and maximum points of the cuboid.
This is 6 floats or 24 bytes per AABB.
If there is a scene with 1 million voxels, then the memory consumption would be 24MB.
This may not sound like much, however the AS has extra AABBs for the hierarchy, which will add upto more memory.
To do lighting calculations and other operations, the user would need to access the data inside the voxels.
The graphics API does not allow accessing the data inside the AS, so there would be duplicated data.

\subsection{Data Collection}

Data collection to analyze the performance is done by measuring the frame time and frames per second.
The following configuration is run on 3 different scenes with varying number of voxels.

\begin{itemize}
    \itemsep0em
    \item New York City: 4.3 million voxels
    \item Operating Room: 5.2 million voxels
    \item Church: 13.6 million voxels
\end{itemize}

The ray tracing algorithm is run for 4096 frames, and the average frame time is calculated.
From the average frame time, the average frames per second is calculated, by $FPS = \frac{1}{Average Frame Time}$.

Two methods of intersection tests are used:
\begin{itemize}
    \itemsep0em
    \item Exact Intersection: The exact intersection is calculated for every voxel.
    \item Approximate Intersection: The closest hit is approximated and the exact intersection is calculated in the closest hit stage.
    Described in Section \ref{sec:OptimizingIntersection}.
\end{itemize}

Additionally, NVIDIA's Nsight Graphics is used to analyze the performance of the GPU.
This allows to analyze specific instructions that are taking the most time.
The memory consumption will be analyzed in the same tool, to see accurate memory usage.

\section{Results}

This essay's analysis is based upon NVIDIA 3060ti GPU on Windows 11 using DirectX 12.
Results may vary on different hardware and software configurations.

\subsection{Driver Conformance}

Graphics APIs are high level interfaces that allow the user to interact with the GPU,
and the driver acts as a middleman between the API and the GPU Hardware.
The code used in this essay has been written on Vulkan, and DirectX 12 graphics APIs,
and the NVIDIA's GPU driver has been found not to conform strictly to either of the specifications.

Wrong information about the ABB that was hit is passed to the intersection and closest hit stages.
The driver is merging voxels that are close to each other, into a single wide AABB.
The user does not know that the AABB was merged and expects it to act as individual voxels.
It is important to note, that the driver may merge the AABBs for optimization, but it should still act as if the AABBs were not merged.

\begin{figure}[H]
    \begin{center}
        \includegraphics[scale=0.5]{Voxel-Merging}
    \end{center}
    \caption{
        The expected behavior compared to the real behavior.
        }
        \label{fig:Voxel-Merging}
    \end{figure}
    
The merged AABB in Figure \ref{fig:Voxel-Merging} is blue,
because the driver reports that the primitive hit is the blue voxel even for the right side of the merged AABB.

The exact intersection method does not suffer from this issue, however the approximate intersection does.
For the sake of this essay, the issue is ignored because the issue has been reported to developers.
The usability for real-time applications is impacted severely by this issue if not resolved.
This issue is not unique to this essay, as few developers have reported the same issue.

% TODO: add source to nvidia forums

\subsection{Performance Data}

\begin{table}[H]
    \centering
    \caption{Exact Intersection Performance Data }
    \vspace{0.5cm}
    \label{tab:Exact-Performance-Data}
    \begin{tabular}{c||c|c|c|}
     Scene (voxels)             & Frame Time (ms)    & Frame Per Second \\ \toprule
    New York City (4.3 mil)     & 3.07               & 324              \\
    Operating Room (5.2 mil)    & 10.7               & 93               \\
    Church                      & 11.0               & 91               \\
    \end{tabular}
\end{table}

\begin{table}[H]
    \centering
    \caption{Approximate Intersection Performance Data }
    \vspace{0.5cm}
    \label{tab:Approx-Performance-Data}
    \begin{tabular}{c||c|c|c|}
     Scene (voxels)             & Frame Time (ms)    & Frame Per Second \\ \toprule
    New York City (4.3 mil)     & 3.53               & 282              \\
    Operating Room (5.2 mil)    & 10.0               & 100              \\
    Church (13.6 mil)           & 10.7               & 94               \\
    \end{tabular}
\end{table}


\subsection{New York City Scene}

The performance is optimal for the New York City scene, with 4.3 million voxels.
The exact intersection method proves to be faster than the approximate intersection method,
this is good because the exact intersection method is more accurate. Furthermore, the driver
issue discovered in the previous section does not affect the exact intersection method.
The reason behind high performance for the New York City scene is because less rays are traced.
The scene is open, meaning there it is not enclosed, hence rays can escape the scene quickly,
hitting the sky. Most of the rays do not bounce more than once or twice, which is why the performance is high.

The scene is a good representation of a real-time application, because it is open.
Most visualization application are often focusing on a single object and the environment is open.
For example, a medical imaging application would focus on a single organ and rest of the environment would be empty.
The frame time also gives opportunities to add more work for the GPU, such as queing Artifical Intelligence (AI) tasks,
or physics calculations.

\section{Conclusion}



\printbibliography

\end{document}