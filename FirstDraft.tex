\documentclass[12pt]{article}
\usepackage{graphicx}
\usepackage[style=alphabetic, backend=biber]{biblatex}
\graphicspath{ {./images/} }

\addbibresource{figures.bib}

% Preamble
\setlength{\parindent}{0pt}

% Document Information
\title{Optimal Method of Ray Tracing Voxels with Hardware Acceleration in Real-Time}
\author{Srijan Dhungana}
\date{2024}

% Begin Document
\begin{document}

% Title Page
\maketitle
\clearpage

% Table of Contents
\tableofcontents
\clearpage

\section{Motivation}

My first introduction to ray tracing was when NVIDIA announced their RTX series GPUs in 2018.
The idea of simulating light rays in real-time was unreal to me and the results were stunning.
I wanted to make my own hardware ray tracer and so I was introduced to computer graphics.
I have always been fascinated by the aesthetics of voxels based games and I wanted to combine the two.
However, when researching, I found that there was not much information on the fastest method to ray trace a voxel scene with hardware acceleration.
This essay is an attempt to answer that question.

\section{Introduction}

\subsection{Ray Tracing}

Ray tracing is a method to calculate where a given ray (line), intersects
with the environment. This is useful to simulate light rays because of how light behaves. It is used in film
production, video games, optics, medical imaging, architectural visualization,
and many other fields. Physically light rays bounce in the environment, thus
ray tracing is used to calculate the position of intersection where a light ray
hits the environment. Then the programmer is free to repeat the process
and simulate the ray bouncing off into other directions. This process is a
highly parallelizable process, thus it is perfectly suited for GPUs which have
thousands of cores. However, due to how computationally expensive the
process is, it is not feasible to do in real-time without dedicated hardware
acceleration. Due to those limitations, it was only used in non-real-time
applications such as film production and pre-rendered graphics. Hardware
acceleration ray tracing was introduced in 2018 by Nvidia. Since then, ray
tracing has been possible in real-time and further supported by AMD and
Intel GPUs. This has allowed real-time applications to leverage ray-tracing

\subsection{Voxels}

Voxels are a way to represent 3D data. It is similar to pixels in 2D images,
but in 3D space. Essentially, voxels are cubes that are located in 3D space.
They are used in medical imaging, simulations, and video games; they have
similar applications to ray tracing. Voxels are convenient, because they rep-
resent volumetric data, which is difficult to represent with polygons. For
example, a physics simulation of a fluid would be difficult to represent with
polygons, but easy with voxels. Each voxel can store data such as color,
density, temperature, etc. at each point in 3D space. The resolution of the
simulation can also be adjusted easily just by changing the size of the voxels.

\subsection{Research Question}

The research question is: What is the difference in performance between
purely hardware based voxel ray tracing and a mixed software-hardware approach in rendering?

\section{Background Information}

\subsection{Mathematics of Ray Tracing}
\subsubsection{The Ray Equation}

A ray is defined by a point and a direction. The equation of a ray is given by:

\begin{equation}
    R(t) = \vec{o} + t\vec{d}
\end{equation}

where $\vec{o}$ is the origin of the ray, $\vec{d}$ is the direction of the ray, and $t$ is the distance from the origin.
The function $R(t)$ gives the position of the ray at distance $t$ from the origin.
With this equation, any point along the ray can calculated.

\subsubsection{The Intersection Function}

Whenever a ray intersects with a surface, the point of intersection is given by the equation:

\begin{equation}
    R(t) = I(t)
\end{equation}

where $I(t)$ is the intersection function of the surface. To locate the point of intersection,
solving for $t$ is necessary by equating the ray equation with the intersection function. 
If there are negative solutions for $t$, then the ray intersects with the surface. However, 
if $t$ is negative, then the intersection is opposite the direction of the ray, which is not usually desired,
so negative solutions are ignored. The closest hit is desired, so the smallest positive $t$ is chosen.

The intersection test has to happen for every object in the scene to determine the closest intersection.
This is computationally expensive for large scenes, so acceleration structures (AS) are used to decrease the number of intersection tests significantly.
These structures are usually bounding volume hierarchies (BVH) that subdivide the scene into smaller parts until the smallest primitives are reached.

\begin{figure}[h]
    \includegraphics[scale=0.22]{BVH-Visualization}
    \caption{
        Bounding Volume Hierarchy of a bunny. 
        The bunny is divided into smaller bounding volumes until the individual triangles are reached.
        \parencite{Medium:BVH-Visualization}}
    \label{fig:BVH-Visualization}
\end{figure}

When a ray enters a bounding volume, the algorithm only has to test for intersections with the objects in that volume, which is much efficient.
The BVH is a non-trivial tree structure that is constructed every object in the scene and requires a lot of memory, because
it stores the volumes in addition to the objects.

\subsection{Ray Tracing Algorithm}

The ray tracing algorithm is a recursive algorithm that calculates the color of a pixel by tracing rays into the scene.
The scene has a virtual camera that acts like a real camera capturing photons but instead of capturing photons, it shoots rays
into the scene.
This is because a light source emits photons in unmeasurable quantities and it is impossible to simulate all of them and a typical scene has multiple light sources.
Additionally, not all photons reach the camera, so most of the computation is wasted.
When tracing from the camera, the algorithm can simulate the exact paths but it only simulates paths that reach the camera.

The algorithm is as follows for each pixel in the image:
\begin{enumerate}
    \item Calculate a ray direction for the pixel.
    \begin{itemize}
        \item This is dependent on the field of view, focal length, and many other factors such as a real lens.
    \end{itemize}
    \item Trace the ray into the scene and find the {\bf closest} intersection. If there is no intersection, then the ray hits the background.
          This could be the sky or a solid color that acts as ambient light.
    \item If the surface is emissive (light source), then the ray's color is a combination of the light source and the colors of the surfaces it hit along the way and the algorithm stops.
          If it is not emissive, then the ray absorbs some percentage of the surface's color and bounces in another
          direction and the algorithm repeats from step 2.
\end{enumerate}

This algorithm is repeated thousands of times for each pixel in the image and the result is a photorealistic image.
The reason it is repeated is that there can be thousands of paths that reach the camera bouncing from different combinations of surfaces.
Even then, the image is an approximation because the algorithm fails to simulate all the paths that reach the camera.

\subsection{GPU Architecture}

% TODO: Explain how GPUs work and how they are used in ray tracing. Also some 3D vs 1D for SDFs maybe?

\section{Methods}

Below are the two methods that will be compared in this essay.

\subsection{Hardware Acceleration Structure Traversal}

To use an AS it needs to be constructed for the objects in the scene.
Unfortunately, acceleration structure generation is a black box in graphics APIs. 
The user supplies the object's primitives and the GPU driver constructs it.
These primitives are usually triangles or axis aligned bounding boxes (AABB).
AABBs are cuboids that are aligned in the x, y, and z axes.

Cubes can be represented as AABBs, so voxels can be represented as AABBs.
This is useful because the GPU can construct the AS without the user having to do it.
However, the AABBs are not inteded to use as voxels, instead they are a flexible way to enclose user defined objects.
For example, a smooth sphere would not be possible to represent using triangles, but there 
is an intersection function that would render a smoother sphere than triangles ever could.
AABBs are used to enclose the sphere and the GPU will notify the user for any potential hits with the sphere.
This can be done for anything as long as it's enclosed in an AABB.
Because of this, they are not optimized for the voxel use case, where there would be millions of
densely packed AABBs in a scene.

Additionally, the memory consumption is greater for AABBs than for voxels.
AABBs need 2, 3D vectors to represent the minimum and maximum points of the cuboid.
This is 6 floats or 24 bytes per AABB.
If there is a scene with 1 million voxels, then the memory consumption would be 24MB.
This may not sound like much, however the AS has extra AABBs for the hierarchy, which will add upto more memory.
To do lighting calculations and other operations, the user would need to access the data inside the voxels.
The graphics API does not allow accessing the data inside the AS, so the user would have to duplicate the data in memory.
It is inefficient and wasteful to have two copies of the same data in memory.

\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.22]{ClosestHit-Approx}
    \end{center}
    \caption{
        Solving for closest hit candidate without an intersection test.
        Instead the distance from the ray origin to the AABB is calculated and the closest candidate is selected.}
    \label{fig:ClosestHit-Approx}
\end{figure}

There are caveats to using hardware acceleration for voxel ray tracing.
The GPU does not solve for the closest intersection for AABBs, instead it only tells the user if there is a potential hit.
Closest hit has to be solved by the user, since the GPU expects the enclosed object to have a different surface than the AABB.
It is obvious that the GPU is not optimized for voxel ray tracing.
However, the GPU provides a transformation matrix that stores the location of the AABB.
Since expensive intersection tests should be avoided, instead of solving for the intersection, only the distance from the ray origin to the potential AABB can be calculated.
Figure \ref{fig:ClosestHit-Approx} shows solving for the closest candiate without an intersection test.
This much more efficient than solving for the intersection and it ensures the closest candidate is chosen.
After finding the closest candidate, the user can solve for the intersection and determine where the ray hits the voxel.


\subsection{Signed Distance Fields}

Signed distance fields (SDF) used to store distance information to the nearest surface. 
SDFs work like LiDAR, where the sensor measures the distance to the nearest surface to map out the environment.
SDFs are used in ray marching which is a technique to render surfaces. 
Ray marching is a technique where the ray is stepped in small increments and the distance to the nearest surface is calculated.
If the distance is less than a threshold, then the ray has hit the surface, this avoids expensive intersection tests for every object in the scene.
However, the ray has to take steps through the scene which can add up to thousands of steps for a single ray.
This may have worse performance if the signed distance field cannot skip large emptry spaces in the scene, thus
requiring more steps to reach the surface.

\begin{figure}[h]
    \begin{center}
        \includegraphics[scale=0.22]{Voxel-SDF}
    \end{center}
    \caption{
        2D visualization of a SDF. The black areas are empty space and store a positive distance to the nearest surface.
        The white areas are the surface thus store 0 as their distance to the nearest surface.
        \parencite{ByteWrangler:Voxel-SDF}}
    \label{fig:Voxel-SDF}
\end{figure}

The SDF approach in this essay will use a mix of software and hardware acceleration.
Storing the whole scene as a SDF would consume a lot of memory because most of space is empty.
Figure \ref{fig:Voxel-SDF} shows that storing a scene as a SDF would be wasteful because of empty space.
This essay's method will enclose the object tightly. For example, in figure \ref{fig:Voxel-SDF}, an AABB would enclose a 2x2 tightly packed SDF instead of 6x6 which has a lot of empty space.
Hardware accelerated AABBs will enclose the SDFs to skip vast empty spaces in the scene.
Only a certain amount of bits will be used to store the distance to the nearest surface in the SDF.
Varying number of bits (2, 4, 8) will be used to compare the performance of the SDF approach.
Additionally, ray marching is not hardware accelerated, so it will be written in software.

\subsection{Other Algorithms}

\section{Memory Consumption}

\section{Results}

\section{Conclusion}

\printbibliography

\end{document}